{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CDC_LSTM.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RIJFdxIbmNPR","colab_type":"text"},"source":["## Link with github project folder"]},{"cell_type":"code","metadata":{"id":"O0Bs7byMzOgy","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rSZIVzt-mR8o","colab_type":"code","colab":{}},"source":["!git clone https://github.com/acmilannesta/Bert-embedding"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ips8pqmnIfp","colab_type":"code","colab":{}},"source":["!pip install keras_bert\n","from keras_bert import AdamWarmup, calc_train_steps"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8ZAhWzmnOh7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":81},"outputId":"55a89e1c-fce9-44f8-8ab6-73703d10ca68","executionInfo":{"status":"ok","timestamp":1574286555381,"user_tz":300,"elapsed":5190,"user":{"displayName":"Jason Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCRNqBeZjhNQpy4RATemyLQ_uEPDPPZ8iycOQqQFw=s64","userId":"16214674102372443196"}}},"source":["from keras.preprocessing.text import Tokenizer\n","from keras.optimizers import Adam\n","from keras.layers import *\n","from keras.models import Model, load_model\n","from keras.callbacks import Callback, EarlyStopping\n","import pandas as pd\n","import numpy as np\n","import gc\n","import codecs\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import f1_score"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"7m03cUqw3QgR","colab_type":"code","outputId":"89395e9b-68df-4159-ff86-157fbff65eb5","executionInfo":{"status":"ok","timestamp":1574285732466,"user_tz":300,"elapsed":899,"user":{"displayName":"Jason Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCRNqBeZjhNQpy4RATemyLQ_uEPDPPZ8iycOQqQFw=s64","userId":"16214674102372443196"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":55,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IfhfDJJZnVmT","colab_type":"text"},"source":["## Load Dataset"]},{"cell_type":"code","metadata":{"id":"g5lPIhJGnXnA","colab_type":"code","colab":{}},"source":["train = pd.read_csv('Bert-embedding/CDC/train.csv')\n","test = pd.read_csv('Bert-embedding/CDC/test.csv')\n","# Event weight\n","wt = pd.DataFrame(train.event.value_counts()/len(train)).rename(columns={'event':'weight'})\n","wt['event'] = wt.index\n","train = train.merge(wt, how='left', on='event')\n","# Reassign eventcode\n","train['event_idx'] = train.event.map({y:x for x, y in enumerate(np.sort(train.event.unique()))})\n","# Assign weight freqency\n","train['wt_freq'] = np.where(train.weight<0.01, 1, np.where(train.weight<0.05, 2, 3))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gMy2eRN_5X5B","colab_type":"code","outputId":"1fadfda2-d6ae-4eb0-a7ed-0136f5181828","executionInfo":{"status":"ok","timestamp":1574271421784,"user_tz":300,"elapsed":5721,"user":{"displayName":"Jason Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCRNqBeZjhNQpy4RATemyLQ_uEPDPPZ8iycOQqQFw=s64","userId":"16214674102372443196"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(tqdm(train.text.tolist()+test.text.tolist()))\n","\n","def convert_data(data_df, branch='training'):\n","    # data_df.sample(frac=1, random_state=0)\n","    data_df.reset_index(drop=True, inplace=True)\n","    global tokenizer\n","    indices = tokenizer.texts_to_sequences(tqdm(data_df.text.tolist()))\n","    aux = data_df[['age', 'sex']].apply(lambda x: (x - min(x)) / (max(x)-min(x)))\n","    if branch=='training':\n","        targets = data_df['event_idx'] \n","        return indices, np.array(targets), np.array(aux)\n","    else:\n","        return indices, np.array(aux)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 229820/229820 [00:05<00:00, 44644.72it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"WS4xKB4zwYsF","colab_type":"text"},"source":["## Parameter setting"]},{"cell_type":"code","metadata":{"id":"rQkn6hWtwUr_","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 512\n","NUM_EPOCHS = 100\n","NUM_CLASSES = 48"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"USMdJUQoiAbA","colab_type":"code","colab":{}},"source":["import spacy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xOmWGApmjrsj","colab_type":"code","outputId":"37b8cc86-8644-44fb-9082-abdb466848db","executionInfo":{"status":"ok","timestamp":1574282998138,"user_tz":300,"elapsed":138521,"user":{"displayName":"Jason Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCRNqBeZjhNQpy4RATemyLQ_uEPDPPZ8iycOQqQFw=s64","userId":"16214674102372443196"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["!python -m spacy download en_core_web_lg"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting en_core_web_lg==2.1.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n","\u001b[K     |████████████████████████████████| 826.9MB 11.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n","  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255076 sha256=50793a38744453673e4b5cb7b117dbbdc6331dfb7f4e18a42f19fb4e4fab8576\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-w4xb9r_t/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n","Successfully built en-core-web-lg\n","Installing collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-2.1.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_lg')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oWw8VY0Blf9l","colab_type":"code","colab":{}},"source":["import en_core_web_lg\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-_JgPAbXjVWs","colab_type":"code","outputId":"6f72340d-3c89-47f2-f8fa-68eca2c7a42c","executionInfo":{"status":"ok","timestamp":1574286800587,"user_tz":300,"elapsed":129668,"user":{"displayName":"Jason Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCRNqBeZjhNQpy4RATemyLQ_uEPDPPZ8iycOQqQFw=s64","userId":"16214674102372443196"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["text_list = pd.concat([train.text, test.text])\n","\n","nlp = en_core_web_lg.load(disable=['parser','ner','tagger'])\n","nlp.vocab.add_flag(lambda s: s.lower() in spacy.lang.en.stop_words.STOP_WORDS, spacy.attrs.IS_STOP)\n","word_dict = {}\n","word_index = 1\n","lemma_dict = {}\n","docs = nlp.pipe(text_list, n_threads = 2)\n","word_sequences = []\n","for doc in tqdm(docs):\n","    word_seq = []\n","    for token in doc:\n","        if (token.text not in word_dict) and (token.pos_ is not \"PUNCT\"):\n","            word_dict[token.text] = word_index\n","            word_index += 1\n","            lemma_dict[token.text] = token.lemma_\n","        if token.pos_ is not \"PUNCT\":\n","            word_seq.append(word_dict[token.text])\n","    word_sequences.append(word_seq)\n","del docs\n","gc.collect()\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["229820it [01:53, 2020.10it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"C01FunvQx6rR","colab_type":"code","colab":{}},"source":["from nltk.stem import PorterStemmer\n","ps = PorterStemmer()\n","from nltk.stem.lancaster import LancasterStemmer\n","lc = LancasterStemmer()\n","from nltk.stem import SnowballStemmer\n","sb = SnowballStemmer(\"english\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Awrf4F_vxa2","colab_type":"code","colab":{}},"source":["def load_embedding(EMBEDDING_FILE, word_dict, lemma_dict):\n","    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n","    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n","    embed_size = 300\n","    nb_words = len(word_dict)+1\n","    embedding_matrix = np.zeros((nb_words, embed_size), dtype=np.float32)\n","    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1.\n","    print(unknown_vector[:5])\n","    for key in tqdm(word_dict):\n","        word = key\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[word_dict[key]] = embedding_vector\n","            continue\n","        word = key.lower()\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[word_dict[key]] = embedding_vector\n","            continue\n","        word = key.upper()\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[word_dict[key]] = embedding_vector\n","            continue\n","        word = key.capitalize()\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[word_dict[key]] = embedding_vector\n","            continue\n","        word = ps.stem(key)\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[word_dict[key]] = embedding_vector\n","            continue\n","        word = lc.stem(key)\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[word_dict[key]] = embedding_vector\n","            continue\n","        word = sb.stem(key)\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[word_dict[key]] = embedding_vector\n","            continue\n","        word = lemma_dict[key]\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[word_dict[key]] = embedding_vector\n","            continue\n","        if len(key) > 1:\n","            word = correction(key)\n","            embedding_vector = embeddings_index.get(word)\n","            if embedding_vector is not None:\n","                embedding_matrix[word_dict[key]] = embedding_vector\n","                continue\n","        embedding_matrix[word_dict[key]] = unknown_vector                    \n","    return embedding_matrix, nb_words "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vW64MbmJv8QQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":322},"outputId":"e5ac040f-c526-4bb9-865c-2a9aadca1aa2","executionInfo":{"status":"error","timestamp":1574287035445,"user_tz":300,"elapsed":178950,"user":{"displayName":"Jason Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCRNqBeZjhNQpy4RATemyLQ_uEPDPPZ8iycOQqQFw=s64","userId":"16214674102372443196"}}},"source":["embedding_matrix_glove, nb_words = load_embedding('/content/drive/My Drive/CDC Model/embedding/glove.840B.300d.txt', word_dict, lemma_dict)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/44724 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[-1. -1. -1. -1. -1.]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-a15194d85d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_matrix_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/CDC Model/embedding/glove.840B.300d.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemma_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-91e325e6602b>\u001b[0m in \u001b[0;36mload_embedding\u001b[0;34m(EMBEDDING_FILE, word_dict, lemma_dict)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'correction' is not defined"]}]},{"cell_type":"code","metadata":{"id":"XGwXEcBFAnVU","colab_type":"code","colab":{}},"source":["np.save('drive/My Drive/CDC Model/embedding/embedding_matrix_wide', embedding_matrix)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gmf53mByvg2W","colab_type":"code","colab":{}},"source":["# np.save('drive/My Drive/embedding matrix', embedding_matrix)\n","embedding_matrix = np.load('drive/My Drive/CDC Model/embedding matrix.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lxm3_P_fsedP","colab_type":"text"},"source":["## Model Assemble"]},{"cell_type":"code","metadata":{"id":"9wkj3GQXsgK9","colab_type":"code","outputId":"d5641244-d944-493e-c8bb-8cdd31f3d212","executionInfo":{"status":"ok","timestamp":1573244356097,"user_tz":300,"elapsed":488,"user":{"displayName":"Jason Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCRNqBeZjhNQpy4RATemyLQ_uEPDPPZ8iycOQqQFw=s64","userId":"16214674102372443196"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def model_build():\n","    global embedding_matrix\n","    global NUM_CLASSES\n","    \n","    words = Input(shape=(None, ))\n","    aux = Input(shape=(2, ))\n","\n","    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n","    x = SpatialDropout1D(0.3)(x)\n","    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n","    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n","\n","    hidden = concatenate([GlobalMaxPooling1D()(x), GlobalAveragePooling1D()(x)])\n","    hidden = add([hidden, Dense(512, activation='relu')(hidden)])\n","    hidden = add([hidden, Dense(512, activation='relu')(hidden)])\n","    hidden = concatenate([hidden, aux])\n","    result = Dense(NUM_CLASSES, activation='softmax')(hidden)\n","\n","    # decay_steps, warmup_steps = calc_train_steps(\n","    # len(tr),\n","    # batch_size=BATCH_SIZE,\n","    # epochs=EPOCHS\n","    # )\n","\n","    model = Model(inputs=[words, aux], outputs=result)\n","    model.compile(\n","        loss='sparse_categorical_crossentropy',\n","        optimizer=Adam(lr=1e-4),\n","        metrics= ['sparse_categorical_accuracy']\n","    )\n","    return model"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'add_2/add:0' shape=(?, 512) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"IX1mfWXn56uM","colab_type":"code","outputId":"2fa21ebc-5d67-4332-fe7d-829bc63e3237","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["del model\n","gc.collect()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["975"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"markdown","metadata":{"id":"bjjp9IqSwdJM","colab_type":"text"},"source":["## Data generator"]},{"cell_type":"code","metadata":{"id":"ZZgAWx1DwcsS","colab_type":"code","colab":{}},"source":["def seq_padding(X, padding=0):\n","    L = [len(x) for x in X]\n","    ML = max(L)\n","    return np.array([np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x for x in X])\n","\n","class data_generator:\n","    def __init__(self, data, batch_size=BATCH_SIZE, branch='train'):\n","        self.data = data\n","        self.batch_size = batch_size\n","        self.branch = branch\n","        self.steps = len(self.data) // self.batch_size\n","        if len(self.data) % self.batch_size != 0:\n","            self.steps += 1\n","\n","    def __len__(self):\n","        return self.steps\n","\n","    def __iter__(self):\n","        while True:\n","            if self.branch == 'train':\n","                np.random.shuffle(self.data)\n","            for i in range(self.steps):\n","                d = self.data[i * self.batch_size: (i + 1) * self.batch_size]\n","                X1 = seq_padding([x[0] for x in d])\n","                if self.branch != 'test':\n","                    Y = np.array([x[1] for x in d])\n","                    aux = np.array([x[2] for x in d])\n","                    yield [X1, aux], Y\n","                else:\n","                    aux = np.array([x[1] for x in d])\n","                    yield [X1, aux]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UHxdeeQl7IL-","colab_type":"text"},"source":["## Interval evaluation and model training"]},{"cell_type":"code","metadata":{"id":"4_cSeaqJkCk-","colab_type":"code","colab":{}},"source":["class IntervalEvaluation(Callback):\n","    def __init__(self, validation_data, label, score=0, maxscore=0, count=0, interval=3000, patience=3, savethreshold=0.84):\n","        super(Callback, self).__init__()\n","        self.seen = 0\n","        self.interval = interval\n","        self.validation_data = validation_data\n","        self.label = label\n","        self.score = score\n","        self.maxscore = maxscore\n","        self.count = count\n","        self.patience = patience\n","        self.savethreshold = savethreshold\n","    def on_batch_end(self, batch, logs={}):\n","        self.seen += logs.get('num_steps', 1)\n","        if self.seen % self.interval == 0:\n","            y_pred = self.model.predict_generator(self.validation_data.__iter__(), len(self.validation_data))\n","            score = f1_score(self.label, np.argmax(y_pred, 1), average='weighted')\n","            print(\" - batch: {:d} - score: {:.4f}\".format(self.seen, score))\n","            if self.maxscore>=0.85:\n","                self.patience=2\n","            if (score < self.score):\n","                self.score = score\n","                self.count+=1\n","                if self.count==self.patience:\n","                    self.model.stop_training=True\n","            elif score > self.maxscore:\n","                self.score = score\n","                self.maxscore = score\n","                self.count = 0\n","                if self.maxscore > self.savethreshold:\n","                    self.model.save('lstm_model.h5')\n","            else:\n","                self.score = score\n","                self.count = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmRPvlt6_i86","colab_type":"code","colab":{}},"source":["np.save('drive/My Drive/CDC Model/oof/test_lstm_oof.npy', pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvqsH_lz_0FS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"coVyQmw-jqDR","colab_type":"code","outputId":"e7f5780d-ebcb-4736-b2e0-e7ee835792b9","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# test_x, test_aux = convert_data(test, branch='test')\n","kf = StratifiedKFold(n_splits=5, random_state=0)\n","pred = np.zeros((len(test), NUM_CLASSES))\n","idx = [x for x in kf.split(train, train.wt_freq)]\n","for i, (tr_idx, val_idx) in enumerate(idx[3:]):\n","    print('Fold - {:}'.format(i+1))\n","    tr, val = train.loc[tr_idx], train.loc[val_idx]\n","    tr_x, tr_y, tr_aux = convert_data(tr)\n","    val_x, val_y, val_aux = convert_data(val)\n","    model = model_build()\n","    train_D = data_generator(list(zip(tr_x, tr_y, tr_aux)))\n","    valid_D = data_generator(list(zip(val_x, val_y, val_aux)), branch='valid')\n","\n","    ival = IntervalEvaluation(\n","        validation_data=valid_D, \n","        label=val_y, \n","        interval = len(train_D)\n","        )\n","    model.fit_generator(\n","        train_D.__iter__(),\n","        steps_per_epoch=len(train_D),\n","        epochs=NUM_EPOCHS,\n","        callbacks = [ival]\n","    )\n","    model = load_model('lstm_model.h5')\n","    # oof_pred = model.predict_generator(valid_D.__iter__(), len(valid_D), verbose=1)\n","    # train.loc[val_idx, 'lstm'] = np.argmax(oof_pred, 1)\n","    # print('oof - {:} f1_score - {:.4f}'.format(i+1, f1_score(val_y, np.argmax(oof_pred, 1), average='weighted')))\n","    test_D = data_generator(list(zip(test_x, test_aux)), branch='test')\n","    pred += model.predict_generator(test_D.__iter__(), len(test_D), verbose=1) / kf.get_n_splits()\n","    del model\n","    gc.collect()\n","    # train.to_csv('drive/My Drive/CDC Model/oof/train_lstm_oof.csv', index=False)\n","test['lstm'] = np.argmax(pred, 1)\n","test.to_csv('drive/My Drive/CDC Model/oof/test_lstm_oof.csv', index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["  4%|▍         | 4625/123166 [00:00<00:02, 46248.61it/s]"],"name":"stderr"},{"output_type":"stream","text":["Fold - 1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 123166/123166 [00:02<00:00, 49902.97it/s]\n","100%|██████████| 30790/30790 [00:00<00:00, 52230.69it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","240/241 [============================>.] - ETA: 0s - loss: 2.0475 - sparse_categorical_accuracy: 0.4302 - batch: 241 - score: 0.6042\n","241/241 [==============================] - 90s 371ms/step - loss: 2.0444 - sparse_categorical_accuracy: 0.4310\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/100\n","240/241 [============================>.] - ETA: 0s - loss: 1.1250 - sparse_categorical_accuracy: 0.6540 - batch: 482 - score: 0.7087\n","241/241 [==============================] - 70s 289ms/step - loss: 1.1248 - sparse_categorical_accuracy: 0.6540\n","Epoch 3/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.9472 - sparse_categorical_accuracy: 0.7065 - batch: 723 - score: 0.7424\n","241/241 [==============================] - 69s 286ms/step - loss: 0.9462 - sparse_categorical_accuracy: 0.7069\n","Epoch 4/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.8593 - sparse_categorical_accuracy: 0.7320 - batch: 964 - score: 0.7597\n","241/241 [==============================] - 69s 287ms/step - loss: 0.8593 - sparse_categorical_accuracy: 0.7320\n","Epoch 5/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.7942 - sparse_categorical_accuracy: 0.7522 - batch: 1205 - score: 0.7801\n","241/241 [==============================] - 70s 288ms/step - loss: 0.7943 - sparse_categorical_accuracy: 0.7521\n","Epoch 6/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.7492 - sparse_categorical_accuracy: 0.7639 - batch: 1446 - score: 0.7895\n","241/241 [==============================] - 70s 290ms/step - loss: 0.7493 - sparse_categorical_accuracy: 0.7639\n","Epoch 7/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.7160 - sparse_categorical_accuracy: 0.7743 - batch: 1687 - score: 0.7946\n","241/241 [==============================] - 69s 288ms/step - loss: 0.7159 - sparse_categorical_accuracy: 0.7744\n","Epoch 8/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.6865 - sparse_categorical_accuracy: 0.7838 - batch: 1928 - score: 0.8025\n","241/241 [==============================] - 69s 288ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.7840\n","Epoch 9/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.6595 - sparse_categorical_accuracy: 0.7913 - batch: 2169 - score: 0.8101\n","241/241 [==============================] - 70s 289ms/step - loss: 0.6594 - sparse_categorical_accuracy: 0.7914\n","Epoch 10/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.6382 - sparse_categorical_accuracy: 0.7967 - batch: 2410 - score: 0.8140\n","241/241 [==============================] - 70s 290ms/step - loss: 0.6378 - sparse_categorical_accuracy: 0.7967\n","Epoch 11/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.6177 - sparse_categorical_accuracy: 0.8040 - batch: 2651 - score: 0.8150\n","241/241 [==============================] - 69s 287ms/step - loss: 0.6176 - sparse_categorical_accuracy: 0.8041\n","Epoch 12/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.6001 - sparse_categorical_accuracy: 0.8086 - batch: 2892 - score: 0.8236\n","241/241 [==============================] - 69s 286ms/step - loss: 0.6002 - sparse_categorical_accuracy: 0.8086\n","Epoch 13/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.5884 - sparse_categorical_accuracy: 0.8131 - batch: 3133 - score: 0.8228\n","241/241 [==============================] - 69s 286ms/step - loss: 0.5878 - sparse_categorical_accuracy: 0.8132\n","Epoch 14/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.5730 - sparse_categorical_accuracy: 0.8170 - batch: 3374 - score: 0.8275\n","241/241 [==============================] - 69s 288ms/step - loss: 0.5738 - sparse_categorical_accuracy: 0.8169\n","Epoch 15/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.5624 - sparse_categorical_accuracy: 0.8197 - batch: 3615 - score: 0.8314\n","241/241 [==============================] - 69s 285ms/step - loss: 0.5621 - sparse_categorical_accuracy: 0.8197\n","Epoch 16/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.5517 - sparse_categorical_accuracy: 0.8230 - batch: 3856 - score: 0.8314\n","241/241 [==============================] - 69s 286ms/step - loss: 0.5517 - sparse_categorical_accuracy: 0.8230\n","Epoch 17/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.5404 - sparse_categorical_accuracy: 0.8267 - batch: 4097 - score: 0.8308\n","241/241 [==============================] - 69s 287ms/step - loss: 0.5402 - sparse_categorical_accuracy: 0.8267\n","Epoch 18/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.5297 - sparse_categorical_accuracy: 0.8294 - batch: 4338 - score: 0.8332\n","241/241 [==============================] - 69s 288ms/step - loss: 0.5297 - sparse_categorical_accuracy: 0.8294\n","Epoch 19/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.5221 - sparse_categorical_accuracy: 0.8317 - batch: 4579 - score: 0.8368\n","241/241 [==============================] - 69s 287ms/step - loss: 0.5221 - sparse_categorical_accuracy: 0.8317\n","Epoch 20/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.5144 - sparse_categorical_accuracy: 0.8339 - batch: 4820 - score: 0.8395\n","241/241 [==============================] - 69s 286ms/step - loss: 0.5142 - sparse_categorical_accuracy: 0.8340\n","Epoch 21/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.5052 - sparse_categorical_accuracy: 0.8361 - batch: 5061 - score: 0.8401\n","241/241 [==============================] - 90s 373ms/step - loss: 0.5056 - sparse_categorical_accuracy: 0.8360\n","Epoch 22/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.5000 - sparse_categorical_accuracy: 0.8388 - batch: 5302 - score: 0.8403\n","241/241 [==============================] - 71s 293ms/step - loss: 0.5005 - sparse_categorical_accuracy: 0.8386\n","Epoch 23/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.4902 - sparse_categorical_accuracy: 0.8412 - batch: 5543 - score: 0.8403\n","241/241 [==============================] - 69s 288ms/step - loss: 0.4902 - sparse_categorical_accuracy: 0.8413\n","Epoch 24/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.4851 - sparse_categorical_accuracy: 0.8424 - batch: 5784 - score: 0.8418\n","241/241 [==============================] - 70s 290ms/step - loss: 0.4850 - sparse_categorical_accuracy: 0.8425\n","Epoch 25/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.4810 - sparse_categorical_accuracy: 0.8437 - batch: 6025 - score: 0.8449\n","241/241 [==============================] - 70s 291ms/step - loss: 0.4810 - sparse_categorical_accuracy: 0.8437\n","Epoch 26/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.4710 - sparse_categorical_accuracy: 0.8470 - batch: 6266 - score: 0.8460\n","241/241 [==============================] - 70s 291ms/step - loss: 0.4709 - sparse_categorical_accuracy: 0.8472\n","Epoch 27/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.4664 - sparse_categorical_accuracy: 0.8477 - batch: 6507 - score: 0.8447\n","241/241 [==============================] - 69s 288ms/step - loss: 0.4664 - sparse_categorical_accuracy: 0.8476\n","Epoch 28/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.4613 - sparse_categorical_accuracy: 0.8492 - batch: 6748 - score: 0.8461\n","241/241 [==============================] - 70s 290ms/step - loss: 0.4614 - sparse_categorical_accuracy: 0.8492\n","Epoch 29/100\n","240/241 [============================>.] - ETA: 0s - loss: 0.4579 - sparse_categorical_accuracy: 0.8508 - batch: 6989 - score: 0.8453\n","241/241 [==============================] - 70s 289ms/step - loss: 0.4579 - sparse_categorical_accuracy: 0.8508\n","Epoch 30/100\n","119/241 [=============>................] - ETA: 32s - loss: 0.4479 - sparse_categorical_accuracy: 0.8528"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OuQd7Z9a7MAh","colab_type":"text"},"source":["## Predict on testing set"]},{"cell_type":"code","metadata":{"id":"t8uKKrgj7LpA","colab_type":"code","colab":{}},"source":["class test_generator:\n","    def __init__(self, data, batch_size=BATCH_SIZE, branch='train'):\n","        self.data = data\n","        self.batch_size = batch_size\n","        self.branch = branch\n","        self.steps = len(self.data) // self.batch_size\n","        if len(self.data) % self.batch_size != 0:\n","            self.steps += 1\n","\n","    def __len__(self):\n","        return self.steps\n","\n","    def __iter__(self):\n","        while True:\n","            for i in range(self.steps):\n","                d = self.data[i * self.batch_size: (i + 1) * self.batch_size]\n","                X1 = seq_padding([x[0] for x in d])\n","                aux = np.array([x[1] for x in d])\n","                yield [X1, aux]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lT7VNM0g7djq","colab_type":"code","outputId":"50c6524a-74e5-4c02-d480-37397aca6768","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# predmodel = load_model('lstm_model_0.8947.h5', custom_objects={'AdamWarmup': AdamWarmup})\n","test_D = test_generator(list(zip(test_text, test[['age', 'sex']].values)))\n","pred_lstm = predmodel.predict_generator(test_D.__iter__(), len(test_D), verbose=1)\n","test['event'] = np.argmax(pred_lstm, 1)\n","test['event'] = test.event.map({x:y for x, y in enumerate(np.sort(train.event.unique()))})"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4742/4742 [==============================] - 237s 50ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oztU26T7gyYV","colab_type":"code","colab":{}},"source":["test.to_csv('solution.csv', index=False)"],"execution_count":0,"outputs":[]}]}